# ğŸš€âœ¨ **PC: Introduction to Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)** âœ¨ğŸš€  


## ğŸ¯ **Goal**  
ğŸ¤– **Understand the basics of Large Language Models (LLMs)** and how **Retrieval-Augmented Generation (RAG)** enhances LLMs for tasks like text generation and answering complex queries. You will learn to use LLMs in combination with a retrieval system to improve performance. No prior experience neededâ€”just bring your curiosity! ğŸš€  

---

## ğŸ“Œ **What You Will Learn** ğŸ§ ğŸ’¡  
âœ… What are **Large Language Models (LLMs)**?  
âœ… What is **Retrieval-Augmented Generation (RAG)**?  
âœ… Setting Up LLM and RAG for Text Generation  
âœ… Running LLM and RAG for Text Generation   
âœ… How to use **RAG** with **Hugging Face** to enhance text generation  
âœ… Hands-on coding with **Google Colab** and **Hugging Face**  

---

## ğŸ¤– **1. What is a Large Language Model (LLM)?**  
### ğŸ§  Understanding LLMs in Simple Terms  
A **Large Language Model (LLM)** is a type of AI model that can understand and generate human-like text. It learns by analyzing massive amounts of text data, recognizing patterns, and predicting words based on context.

### ğŸ“Œ Real-World Examples:  
- âœ… Chatbots like Siri, Google Assistant, ChatGPT ğŸ—£ï¸  
- âœ… AI-powered writing assistants (Grammarly, Jasper AI) âœï¸  
- âœ… Search engines predicting your queries ğŸ”  
- âœ… AI-generated stories and essays ğŸ“–  

---

## ğŸ”§ **2. What is Retrieval-Augmented Generation (RAG)?**  

### ğŸ–¼ï¸ Retrieval-Augmented Generation (RAG) Visual Representation

<img src="https://github.com/user-attachments/assets/28f1e5d6-070b-405f-8a54-87c17ed5fbab" width="600">

Source: [RAG and LLM Integration](https://apmonitor.com/dde/index.php/Main/RAGLargeLanguageModel)

### ğŸ§  How RAG Enhances Large Language Models ğŸ”—  

ğŸ’¡ Think: How do retrieval and generation work together to improve AI responses? ğŸ¤”

Retrieval-Augmented Generation (RAG) is an AI framework that improves large language models (LLMs) by integrating an external knowledge retrieval process. This allows the model to **pull relevant information from a document database** instead of relying only on its pre-trained knowledge.

- **User Query** (ğŸ’¬): A user submits a question, which is then processed by the system to find relevant information.

- **Vector Database & Document Storage** (ğŸ“‚)
  - Documents are **converted into numerical embeddings** using an **encoder model**.
  - These embeddings are stored in a **vector database** for efficient retrieval.

- **Encoder Model** (ğŸ§©)
  - The userâ€™s query is transformed into an **embedding representation**.
  - The system finds the closest related documents using **k-Nearest Neighbors (k-NN)**.

- **Context Retrieval & Augmentation** (ğŸ”â¡ï¸ğŸ“–)
  - The **most relevant documents** are retrieved from the vector database.
  - These documents are **added as extra context** for the LLM before generating a response.

- **Large Language Model (LLM) Processing** (ğŸ§ )
  - The LLM combines its **pre-trained knowledge** with the **retrieved external information**.
  - This **enhances accuracy and reduces hallucination**, improving response quality.

- **Final Answer Generation** (âœ…)
  - The model generates a well-informed response using both internal and retrieved knowledge.
  - The final answer is then **returned to the user**.

---

### **Why RAG Matters?** ğŸš€  
âœ… **More Accurate** â€“ Reduces AI hallucinations by retrieving real-time, external information.  
âœ… **Scalable** â€“ Works with large document collections without needing to retrain the model.  
âœ… **Efficient** â€“ Uses vector search for fast, **semantic** document matching.  

ğŸ“–Traditional LLMs generate responses based on probability distributions learned from training data. RAG mitigates hallucinations by injecting real-time knowledge, making responses more factually grounded.

### ğŸ› ï¸ How Does RAG Work?  
RAG enhances LLMs by integrating **retrieval** and **generation** to provide more accurate responses. Instead of relying solely on pre-trained knowledge, it fetches relevant information from external databases before generating a response.

#### ğŸ“š Steps in RAG:  
1ï¸âƒ£ **Retrieval:** The model searches for relevant documents from a knowledge base.  
2ï¸âƒ£ **Augmentation:** The retrieved data is passed as context to the LLM.  
3ï¸âƒ£ **Generation:** The LLM generates a response based on the retrieved information. 

ğŸ“Œ **Example:**  
- If you ask about a recent scientific breakthrough, RAG can retrieve research papers or trusted sources before forming an answer.  

---

## ğŸ”§ **3. Setting Up LLM and RAG for Text Generation**

## ğŸš€ **Step 1: Open [Google Colab](https://colab.research.google.com/)**

1ï¸âƒ£ Open your browser and go to **[Google Colab](https://colab.research.google.com/)**.  
2ï¸âƒ£ Click **+ New Notebook** to begin.

## ğŸ› ï¸ **Step 2: Set Up Hugging Face Account and Access Token**

1ï¸âƒ£ **Sign up on Hugging Face**: Go to [Hugging Face Sign-Up](https://huggingface.co/join) and create a free account.  
2ï¸âƒ£ **Generate an Access Token**:
   - Click on your profile icon and go to **[Your Account Settings](https://huggingface.co/settings/tokens)**.
   - Scroll down to **Access Tokens** and click **New Token**.
   - Give it a name (e.g., "Colab Access") and select **Read** access.
   - Click **Generate Token** and copy the token.

âœ… Hugging Face account setup complete! Youâ€™re now ready to log in. ğŸ”‘ğŸ‰

## ğŸ“š **Step 3: Login in Colab with the Token**

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cafa63-35d0-8004-bfdc-f36ffb25ae57)

```python
# Import Hugging Face login module
from huggingface_hub import notebook_login  

# Trigger login prompt
notebook_login()  
```

3ï¸âƒ£ **Click Run (â–¶) and follow the instructions.**  

âœ… Logged in successfully! Now, let's verify authentication. ğŸ‰

## ğŸ” **Step 4: Verify Authentication**

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67caface-5ed8-8004-a60c-5132ec7113bd)

```python
# Check if authentication is successful
!huggingface-cli whoami  
```

3ï¸âƒ£ **Click Run (â–¶) and check the output!** 
 
âœ… If it prints your Hugging Face username, the setup is complete! ğŸ‰


---

## ğŸ”§ **4. Running LLM and RAG for Text Generation**

## ğŸ“š **Step 1: Install and Import Required Libraries**

Before importing the libraries, install the necessary dependencies by running the following command:

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cafb46-9940-8004-8618-4f0cb0dfd5aa)

```python
# Install Hugging Face Transformers, FAISS, and datasets
!pip install transformers faiss-cpu datasets  
```

3ï¸âƒ£ **Click Run (â–¶) to install the required packages.**

âœ… Dependencies installed successfully! Now, let's import the necessary libraries. ğŸ“šğŸ‰

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cafbb3-4074-8004-8fd6-58b28b1cdd4d)

```python
# Import required libraries
from transformers import pipeline, RagTokenizer, RagRetriever, RagSequenceForGeneration  
import faiss  
```

3ï¸âƒ£ **Click Run (â–¶) to import the libraries.**

âœ… Libraries imported successfully! Youâ€™re now ready to load a pre-trained RAG model. ğŸš€ğŸ‰

## ğŸ§  **Step 2: Load a Pre-Trained RAG Model**

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cafc54-f3c0-8004-a121-af4a0faa0f5c)

```python
# Define tokenizer model name
tokenizer_model = "facebook/rag-sequence-nq"  

# Load the tokenizer
tokenizer = RagTokenizer.from_pretrained(tokenizer_model)  

# Define the text-generation model name
generation_model = "gpt2"  

# Load the text-generation model
model = pipeline("text-generation", model=generation_model)  
```

3ï¸âƒ£ **Click Run (â–¶) to load the pre-trained RAG model.**

ğŸ“Œ **Note:** When running this step, you may see a prompt asking:

```
Do you wish to run the custom code? [y/N]
```

Type **'y'** and press **Enter** to allow the model to load properly. This is required for some Hugging Face models.

âœ… Pre-trained RAG model loaded successfully! Letâ€™s proceed with querying the model. ğŸ§ ğŸ‰

## ğŸ“š **Step 3: Prepare a Query and Retrieve Information**

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cafcc4-b258-8004-9f15-5b1e7d1d9419)

```python
# Define user query
query = "What is the process of photosynthesis?"  

# Tokenize query
input_dict = tokenizer.prepare_seq2seq_batch(query, return_tensors="pt")  

# Retrieval is disabled as retriever is removed
retrieved_docs = None  
```

3ï¸âƒ£ **Click Run (â–¶) to retrieve documents related to the query.**

âœ… Query prepared successfully! Now, let's generate a response. âœ¨ğŸ‰

## âœ¨ **Step 4: Generate a Response Using the Retrieved Documents**

### **â•ğŸ Add a New Code Cell**  
1ï¸âƒ£ Click **+ Code** in the top left to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code into the new code cell.  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cafd2e-39b4-8004-9c52-ba1ac77e845f)

```python
# Generate response based on retrieved documents
output = model(query, max_length=100, truncation=True)  

# Extract generated text
generated_text = output[0]['generated_text']  

# Print generated response
print("Generated Answer:", generated_text)  
```

3ï¸âƒ£ **Click Run (â–¶) to generate a response based on the retrieved documents.**

ğŸ“Œ **Expected Output:**

- The model should generate a relevant and coherent answer about the process of photosynthesis based on the retrieved information.

âœ… Response generated successfully! You now have an AI-powered system retrieving and generating answers. ğŸš€ğŸ‰


---


ğŸ† Exercise: Try It Yourself! ğŸ¯

Now that you have learned how to retrieve and generate responses using RAG, try this challenge on your own!

1ï¸âƒ£ Modify the query to ask about a different topic, such as climate change, machine learning, or the history of AI.    
2ï¸âƒ£ Run the code and analyze how the retrieved documents influence the generated response.    
3ï¸âƒ£ Experiment by changing the model parameters (e.g., max_length) to see how the output changes.

ğŸ“Œ Bonus Challenge: Try integrating a different retrieval dataset from Hugging Face and see how it impacts the performance! ğŸš€

---

## ğŸ¯ **5. Wrap-Up & Next Steps**  
ğŸ‰ Congratulations! You learned how to:  
âœ… Use a **Large Language Model (LLM)** for text generation.  
âœ… Implement **Retrieval-Augmented Generation (RAG)** to improve text generation.  
âœ… Use **Hugging Face** for easy access to pre-trained models and retrieval systems.  

ğŸš€ **Next Workshop:** [ğŸ” Ethical AI & Future Trends](https://github.com/DrAlzahrani/HPC-AI-Resources/wiki/personal-computer-ethical-ai)  

### ğŸ”— **Additional AI Resources** ğŸ“š   

- [Google Colab Guide](https://colab.research.google.com/)     
- [Python Introduction](https://www.w3schools.com/python/python_intro.asp)<br>
âš  **Warning:** Please use only the two green buttons (â€œPreviousâ€ and â€œNextâ€) to navigate the tutorial. Avoid clicking on other links to prevent being redirected to ads.      
- [What is retrieval-augmented generation (RAG)?](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-retrieval-augmented-generation-rag)
- [AWS: What is Retrieval-Augmented Generation (RAG)?](https://aws.amazon.com/what-is/retrieval-augmented-generation/)


ğŸ‰ Keep learning AI, and see you at the next workshop! ğŸš€