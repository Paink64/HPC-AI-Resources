# ğŸš€âœ¨ HPC: Introduction of Large Language Models (LLMs) âœ¨ğŸš€

## ğŸ¯ Goal
ğŸ¤– Learn how to efficiently run Large Language Models (LLMs) on **High-Performance Computing (HPC) systems**, leveraging **JupyterLab** for scalable text generation and question-answering tasks. Whether you're new to LLMs or HPC, this hands-on workshop will guide you through the essentials! ğŸš€

---

## ğŸ“Œ What You Will Learn ğŸ§ ğŸ’¡
âœ… Why use **HPC** for running LLMs? ğŸš€  
âœ… How to access and navigate **CSUSB HPC & JupyterLab** ğŸ–¥ï¸  
âœ… Install essential Libraries and Kaggle dataset âœï¸  
âœ… How to run **pre-trained LLMs on HPC** for faster processing â©  
âœ… Using **Hugging Face Transformers** for text generation and QA  
âœ… Working with a **Kaggle dataset** for real-world applications ğŸ“Š  

---

## ğŸ† 1. Why use **HPC** for running LLMs? ğŸš€
### ğŸš€ The Power of High-Performance Computing (HPC)
LLMs are computationally expensive! Running them on personal devices can be **slow**, **memory-intensive**, and sometimes **impossible**. HPC systems solve this by:
- **Parallelizing workloads** for faster execution âš¡
- **Providing GPU acceleration** to handle large-scale deep learning models ğŸ®
- **Handling large datasets** efficiently ğŸ“Š

ğŸ’¡ *Think: What AI tasks can benefit from HPC? Jot down your ideas! ğŸ“*

---

## ğŸ”¥ 2. How to access and navigate **CSUSB HPC & JupyterLab** ğŸ–¥ï¸

Once you sign in to the CSUSB HPC portal, follow these steps to configure and launch your server:

### Step 1: Access the HPC JupyterHub   
1ï¸âƒ£ Log into [CSUSB HPC Portal](https://csusb-hpc.nrp-nautilus.io/) using your school credentials.   
2ï¸âƒ£ Click CI Logon and authenticate.

### Step 2: Configure Your Server   
1ï¸âƒ£ Click Start My Server or Launch Server if prompted.   
2ï¸âƒ£ Under Advanced Options, adjust the following:   

- GPUs: 2
- GPU Type: Leave as Any
- Cores: 4 (default)
- RAM: 16 GB (default)
 
3ï¸âƒ£ Under Image, select:   
âœ… Stack Datascience   
### Step 3: Start Your Server   
1ï¸âƒ£ Scroll down and click Start to launch the server.   
2ï¸âƒ£ Wait for the server to initialize. Once it is ready, JupyterHub will open in a new tab.

âœ… Now your server is ready for the workshop! ğŸš€

---

## ğŸ”§ 3. Install essential Libraries and Kaggle dataset âœï¸  

### **â•ğŸ Add a New Code Cell**  
  
1ï¸âƒ£ Click **+ Code** in Jupyter Notebook to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code:  
    
ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cb1712-6940-8004-9dd6-df6e5b2542c1)
```bash
# Install essential Python libraries for data manipulation and analysis
pip install --user pandas  

# Install seaborn for data visualization, useful for plotting and analyzing trends
pip install --user seaborn  

# Install matplotlib for creating static, animated, and interactive visualizations
pip install --user matplotlib  

# Install Kaggle API to download datasets directly from Kaggle into the HPC environment
pip install --user kaggle  

# Temporarily add Kaggle to system PATH
export PATH=~/.local/bin:$PATH  

# Permanently add Kaggle to system PATH
echo 'export PATH=~/.local/bin:$PATH' >> ~/.bashrc  

# Apply changes immediately
source ~/.bashrc  

# Create a new directory for dataset storage
mkdir -p ~/playstore_data  

# Navigate into the dataset directory
cd ~/playstore_data  

# Download the Google Playstore dataset from Kaggle
kaggle datasets download -d gauthamp10/google-playstore-apps  

# Unzip the downloaded dataset
unzip google-playstore-apps.zip  

# List extracted files to confirm successful download
ls -lh  
```

3ï¸âƒ£ **Click Run (â–¶) and check the output!** 

âœ… **Success!** Dataset downloaded and ready for analysis. ğŸ‰

---

## ğŸ¤– 4. How to run **pre-trained LLMs on HPC** for faster processing â© 

## ğŸ—ï¸ Step 1: Load Dataset into Jupyter Notebook

1ï¸âƒ£ In **JupyterLab**, open a **new notebook** (Python 3 Kernel).  
2ï¸âƒ£ In the first code cell, run:  
  
ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cb1794-47c4-8004-86e4-4231aa963ed4)

```python
# Import Pandas library
import pandas as pd  

# Define dataset file path
dataset_path = "~/playstore_data/Google-Playstore.csv"  

# Load dataset into a Pandas DataFrame
playstore_df = pd.read_csv(dataset_path)  

# Display the first few rows of the dataset
print("Dataset Preview:")  
print(playstore_df.head())  

# Extract column names for reference
column_names = playstore_df.columns.tolist()  

# Print column names
print("\nColumn Names:", column_names)  
```
3ï¸âƒ£ **Click Run (â–¶) and check the output!** 
 
âœ… **Success!** Dataset is now loaded into your notebook and ready for analysis.

## âœï¸ Step 2: Using **Hugging Face Transformers** for text generation and QA  
This step demonstrates how an LLM can generate text based on a given prompt.

### **â•ğŸ Add a New Code Cell**    
1ï¸âƒ£ Click **+ Code** in Jupyter Notebook to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code:  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cb17fa-9d94-8004-82cf-28100b37fbdb)

3ï¸âƒ£ import the necessary library:
```python
# Import Hugging Face pipeline
from transformers import pipeline  
```
4ï¸âƒ£ Load the GPT-2 model, which is a pre-trained language model:
```python
# Define text generation task
task = "text-generation"  

# Specify model name
model_name = "gpt2"  

# Load the pre-trained GPT-2 model
generator = pipeline(task, model=model_name)  
```
5ï¸âƒ£ Generate text based on a given prompt:
```python
# Define input prompt
prompt = "Once upon a time, in a futuristic city,"  

# Set maximum number of new tokens
max_tokens = 50  

# Generate text based on prompt
output = generator(prompt, max_new_tokens=max_tokens)  

# Extract generated text
generated_story = output[0]['generated_text']  

# Print generated story
print("Generated Story:")  
print(generated_story)  
```
6ï¸âƒ£ **Click Run (â–¶) and check the output!** 
  
âœ… Text generation complete! You should now see a futuristic story generated by GPT-2. ğŸ“–ğŸš€ğŸ‰

ğŸ’¡ **Challenge:** Modify the `prompt` variable to explore different stories.

## ğŸ¤” Step 3: Analyze App Descriptions with GPT-2
Instead of manually writing descriptions, letâ€™s use GPT-2 to generate app descriptions automatically.


### **â•ğŸ Add a New Code Cell**    
1ï¸âƒ£ Click **+ Code** in Jupyter Notebook to add a new code cell.  
2ï¸âƒ£ Copy and paste the following code:  

ğŸ”— [ChatGPT explanation for the code](https://chatgpt.com/share/67cb1863-4454-8004-844c-41cb9b1f197e)

3ï¸âƒ£ Extract app names and format them into prompts:
```python
# Extract app names from dataset
app_names = playstore_df['App Name'].dropna()  

# Convert app names into prompts for description generation
app_descriptions = [f"{str(app)} is an app that " for app in app_names]  
```
4ï¸âƒ£ Use GPT-2 to generate descriptions for each app:
```python
# Select first 10 app names to generate descriptions
selected_apps = app_descriptions[:10]  

# Set max tokens for generated descriptions
max_description_tokens = 50  

# Generate text for app descriptions
outputs = generator(selected_apps, max_new_tokens=max_description_tokens)  
```
5ï¸âƒ£ Print generated app descriptions:
```python
# Print generated descriptions for each app
print("Generated App Descriptions:")  
for app, output in zip(playstore_df['App Name'][:10], outputs):  
    generated_text = output[0]['generated_text']  
    print(f"{app}: {generated_text}")  
```
6ï¸âƒ£ **Click Run (â–¶) and check the output!** 

âœ… App descriptions generated! You should now see AI-generated descriptions for the first 10 apps. ğŸ“±âœ¨ğŸ‰

ğŸ’¡ **Challenge:** Try processing more than 10 apps to analyze the variety of AI-generated text.

---

## ğŸ¯ 4. Wrap-Up & Next Steps
ğŸ‰ Congratulations! You learned how to:
- âœ… Access **HPC & JupyterLab** ğŸ–¥ï¸
- âœ… Install **LLM dependencies on HPC** ğŸ”§
- âœ… Download and analyze **Kaggle datasets** ğŸ“Š
- âœ… Use **GPT-2 for text generation** âœï¸
- âœ… Apply AI to real-world app descriptions ğŸ—ï¸

ğŸš€ **Next Workshop:** [ğŸ“š LLM + RAG (AI-Powered Search)](https://github.com/DrAlzahrani/HPC-AI-Resources/wiki/hpc-llm-rag)


### ğŸ”— Additional Resources ğŸ“š
- [Project Jupyter Documentation](https://docs.jupyter.org/en/latest/)     
- [Python Introduction](https://www.w3schools.com/python/python_intro.asp)<br> 
âš  **Warning:** Please use only the two green buttons (â€œPreviousâ€ and â€œNextâ€) to navigate the tutorial. Avoid clicking on other links to prevent being redirected to ads.     
- [CSUSB: High-Performance Computing (HPC) Resources](https://www.csusb.edu/faculty-center-for-excellence/idat/high-performance-computing)   
- [Microsoft Learn: Introduction to large language models](https://learn.microsoft.com/en-us/training/modules/introduction-large-language-models/)

ğŸ‰ **Keep exploring AI, and see you at the next workshop!** ğŸš€